{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMvr4eGmGzNhlZFfxCI1Va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaejunchoe/HAIDS-Lab/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMShr0AZLfiA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Local 문맥을 학습하고 단어 간 가까운 상호작용 정보를 추출.\n",
        "# Local 문맥에서 단어 간 상호작용을 학습하기 위해 설계된 Attention 레이어.\n",
        "class LocalAttention(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, win_size, out_channels):\n",
        "        super(LocalAttention, self).__init__()                                                                     # 'win_size = 5'를 통해 단어 주변의 문맥 정의.\n",
        "\n",
        "        self.win_size = win_size\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 1, kernel_size=(win_size, embed_size)),                                                   # CNN 기반으로 local 문맥의 중요도를 변환하는 Attention_layer\n",
        "            nn.Sigmoid())                                                                                          # 'win_size = 5'를 고려하여 각 단어의 중요도를 0~1로 표현 -> keypoint: win_size = 5\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(1, out_channels, kernel_size=(1, embed_size)),                                               # Local 문맥을 처리하는 CNN Layer\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d((input_size, 1)))                                                                         # 문맥 정보를 집약해 최종적으로 input_size인 10,000으로 Feature map 생성\n",
        "\n",
        "\n",
        "    ## input data를 padding하고 Attention layer 및 CNN에 전달하여 처리된 output 반환.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Padding dynamically to ensure compatibility\n",
        "        #padding = torch.zeros(x.size(0), (self.win_size - 1) // 2, x.size(-1))\n",
        "        padding = torch.zeros(x.size(0), (self.win_size - 1) // 2, x.size(-1), device=x.device)                    # Padding 처리.\n",
        "        x_pad = torch.cat((padding, x, padding), 1).unsqueeze(1)\n",
        "\n",
        "        scores = self.attention_layer(x_pad).squeeze(1)                                                            # Attention score 계산: 중요도 계산을 통한 단어별 가중치 적용\n",
        "        out = torch.mul(x, scores).unsqueeze(1)\n",
        "        out = self.cnn(out)                                                                                        # 최종적으로 Local 문맥 정보 변환\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Global 문맥을 학습하고 다양한 길이의 단어 간 상호작용 정보를 추출.\n",
        "# Global 문맥에서 단어 간 상호작용을 학습하기 위한 Attention 레이어.\n",
        "class GlobalAttention(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, out_channels):\n",
        "        super(GlobalAttention, self).__init__()\n",
        "\n",
        "        self.attention_layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 1, kernel_size=(input_size, embed_size)),                                                  # Global 단위의 중요도를 계산하는 CNN 기반의 Attention Layer\n",
        "            nn.Sigmoid())                                                                                           # 입력 데이터의 길이(input_size)를 고려하여 각 단어의 중요도를 0~1로 표현 -> keypoint: 입력 데이터의 길이(input_size)\n",
        "\n",
        "\n",
        "        ## cnn_1,2,3: Global 문맥의 처리를 위한 CNN Layer\n",
        "        ## 나머지 구성은 동일함.\n",
        "\n",
        "\n",
        "        self.cnn_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, out_channels, kernel_size=(2, embed_size)),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d((input_size - 2 + 1, 1)))\n",
        "        self.cnn_2 = nn.Sequential(\n",
        "            nn.Conv2d(1, out_channels, kernel_size=(3, embed_size)),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d((input_size - 3 + 1, 1)))\n",
        "        self.cnn_3 = nn.Sequential(\n",
        "            nn.Conv2d(1, out_channels, kernel_size=(4, embed_size)),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d((input_size - 4 + 1, 1)))\n",
        "\n",
        "\n",
        "    # CNN 필터 크기별로 Global 문맥을 처리하는 함수\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        score = self.attention_layer(x)\n",
        "        out = torch.mul(x, score)\n",
        "        return self.cnn_1(out), self.cnn_2(out), self.cnn_3(out)\n",
        "\n",
        "\n",
        "\n",
        "# 사용자와 아이템 리뷰 데이터를 처리하고, 로컬 및 전역 Attention 메커니즘을 적용한 후 예측 값을 생성하는 메인 모델.\n",
        "# User와 Item review를 기반으로 Local과 Global 문맥을 결합하고 최종 Rating을 예측.\n",
        "\n",
        "class CNNDLGA(nn.Module):\n",
        "    def __init__(self, input_size, embed_size=100, win_size=5, channels_local=200, channels_global=100,\n",
        "                 hidden_size=500, output_size=50):\n",
        "        super(CNNDLGA, self).__init__()\n",
        "\n",
        "        self.localAttentionLayer_user = LocalAttention(input_size, embed_size, win_size, channels_local)\n",
        "        self.globalAttentionLayer_user = GlobalAttention(input_size, embed_size, channels_global)\n",
        "        self.localAttentionLayer_item = LocalAttention(input_size, embed_size, win_size, channels_local)\n",
        "        self.globalAttentionLayer_item = GlobalAttention(input_size, embed_size, channels_global)\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        # CNN에서 생성된 Feature map을 고차원 벡터로 변환하는 역할.\n",
        "        self.fcLayer = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),  # 입력 차원을 명시하지 않음\n",
        "            nn.Dropout(0.5),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    # LocalAttentionLayer_user와 GlobalAttentionLayer_user를 사용해 문맥 정보를 추출.\n",
        "    def forward(self, x_user, x_item):\n",
        "        # User side\n",
        "        local_user = self.localAttentionLayer_user(x_user)\n",
        "        global1_user, global2_user, global3_user = self.globalAttentionLayer_user(x_user)\n",
        "        out_user = torch.cat((local_user, global1_user, global2_user, global3_user), 1).view(x_user.size(0), -1)                # CNN 출력을 연결(torch.cat)하여 Fully Conntected Layer로 전달.\n",
        "        out_user = self.fcLayer(out_user)\n",
        "\n",
        "        # Item side\n",
        "        local_item = self.localAttentionLayer_item(x_item)\n",
        "        global1_item, global2_item, global3_item = self.globalAttentionLayer_item(x_item)\n",
        "        out_item = torch.cat((local_item, global1_item, global2_item, global3_item), 1).view(x_item.size(0), -1)                # CNN 출력을 연결(torch.cat)하여 Fully Conntected Layer로 전달.\n",
        "        out_item = self.fcLayer(out_item)\n",
        "\n",
        "        # Combine user and item representations\n",
        "        out = torch.sum(torch.mul(out_user, out_item), 1)                                                                       # 두 출력 벡터를 곱(torch.mul)한 후 합산(torch.sum)하여 최종 rating 예측.\n",
        "        return out\n"
      ]
    }
  ]
}