{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "VI7fQxwtzst0"
      ],
      "authorship_tag": "ABX9TyNcdlMoouJFi7hyWz+xQXQh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaejunchoe/HAIDS-Lab/blob/main/Upload_Transnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 준비준비"
      ],
      "metadata": {
        "id": "VI7fQxwtzst0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7435BnR5e8r",
        "outputId": "63255145-630e-4d0b-8142-5c9d67834d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  fonts-nanum\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 10.3 MB of archives.\n",
            "After this operation, 34.1 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-nanum all 20200506-1 [10.3 MB]\n",
            "Fetched 10.3 MB in 1s (7,547 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 123635 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "## 1번 실행 -> 런타임 다시 시작 -> 2번 실행 -> 3번 실행\n",
        "\n",
        "## 1번\n",
        "\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2번\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', family='NanumBarunGothic')"
      ],
      "metadata": {
        "id": "2m1UYVtZ5olT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3번\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "import seaborn as sns\n",
        "\n",
        "# 나눔고딕 폰트 경로 설정\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "plt.rc('font', family=font_name)\n",
        "\n",
        "# 그래프 그리기 예시\n",
        "data = {'가나다': [10, 15, 7], '라마바': [20, 8, 12]}\n",
        "df = pd.DataFrame(data)\n",
        "sns.barplot(data=df, x='가나다', y='라마바')\n",
        "plt.title('한글 그래프')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "6Col4BxW5oxi",
        "outputId": "628e917a-9560-4420-c29f-643fad34bf09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시작"
      ],
      "metadata": {
        "id": "OTjEGCFql9-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA8nk69CmK9m",
        "outputId": "b8fca896-a67f-4a93-c199-9a7ff74cdf5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 파일 경로\n",
        "train_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/train.csv'\n",
        "valid_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/valid.csv'\n",
        "test_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/test.csv'\n",
        "\n",
        "# 파일 존재 확인\n",
        "for file_path in [train_file, valid_file, test_file]:\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"{file_path} exists.\")\n",
        "    else:\n",
        "        print(f\"{file_path} is missing!\")\n",
        "\n",
        "# 데이터 내용 확인\n",
        "for file_path in [train_file, valid_file, test_file]:\n",
        "    if os.path.exists(file_path):\n",
        "        df = pd.read_csv(file_path, header=None, names=['userID', 'itemID', 'review', 'rating'])\n",
        "        print(f\"\\nContents of {file_path}:\")\n",
        "        print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1oXIk4EsKYV",
        "outputId": "6dccf627-71fe-421f-fbf7-644f2602612c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/train.csv exists.\n",
            "/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/valid.csv exists.\n",
            "/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/test.csv exists.\n",
            "\n",
            "Contents of /content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/train.csv:\n",
            "                         userID      itemID  \\\n",
            "0  AFRMDWBD4RXSHKFZUOH6FGVP5I6Q  B07KJJ2DSH   \n",
            "1  AENNGBGNPATANRDSKCSL5HHBGO4A  B07MGJZ2MH   \n",
            "2  AG2YFAVEZSNFDWKJGHKCYEHM376A  B08D6W9F21   \n",
            "3  AGUFZQ2FSNOAEQ3FOQ4PI5G2FCRQ  B08KWLQD46   \n",
            "4  AHPSOZJQRM54EEZSHNKW63Q22RYA  B0933F8BYP   \n",
            "\n",
            "                                              review  rating  \n",
            "0  thoroughly enjoyed month craft project far not...       5  \n",
            "1  like trying different flavors snacks might lik...       5  \n",
            "2                 love shirts subscription going get       5  \n",
            "3  unoriginal variation style cheap projects easi...       3  \n",
            "4  well made high quality vibrant colors fits wel...       5  \n",
            "\n",
            "Contents of /content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/valid.csv:\n",
            "                         userID      itemID  \\\n",
            "0  AG5TO5QYA32TLI2Y5VWZVODBLYSQ  B07DNLTBG7   \n",
            "1  AFC7DQQYW24ECB7WPZ3LZL4ZEUTQ  B07NL9WZZD   \n",
            "2  AGUCXXETYSB32T3NUTJXMUOVHXTQ  B07DNLTBG7   \n",
            "3  AF4ZXHJ67PTD5TMY3EH4DRT5BYWQ  B07TZN3YST   \n",
            "4  AF3ERSE4FHRXP6PV7MYXBZAMEPOQ  B07MGJZ2MH   \n",
            "\n",
            "                                              review  rating  \n",
            "0  deadpool box came 2 things could bought locall...       2  \n",
            "1  contents cute arrived late suppose halloween b...       3  \n",
            "2                        really nice everything love       5  \n",
            "3  shocked anyone keeps subscription past first m...       1  \n",
            "4  way expensive bought lived japan years miss mu...       5  \n",
            "\n",
            "Contents of /content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/test.csv:\n",
            "                         userID      itemID  \\\n",
            "0  AFABB24ZLP4THNF4OHKQZK4RUMAA  B081W8SGPY   \n",
            "1  AECOVJFGGCNYXJQ5A57ZEAROIKCQ  B086J8Y6BR   \n",
            "2  AHA44HF4RZQAGAJUT7UR6GNL2LQA  B07VBB4GLM   \n",
            "3  AGBXIWAOUXLEBPMAPHJXBFJG24TA  B084ZSS5H1   \n",
            "4  AGJD5E4O4MFG4AIGBKIYP75WPS2A  B08DSKJJ7V   \n",
            "\n",
            "                                              review  rating  \n",
            "0  coffee alright main problem received 4 boxes 4...       3  \n",
            "1  sure ' worth 25 4 year old super excited liked...       3  \n",
            "2  therabox allowed continue scamming like still ...       1  \n",
            "3  daughter excited unboxing keep box unbox smile...       5  \n",
            "4  pitbull destroys toys seconds glad ' ve found ...       5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "iDJszx_kmrgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Config 클래스 정의\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.train_epochs = 15\n",
        "        self.batch_size = 128\n",
        "        self.learning_rate = 0.002          # 초기 학습\n",
        "        self.l2_regularization = 1e-6       # 가중치에 대한 L2 정규화 계\n",
        "        self.learning_rate_decay = 0.99     # 학습이 진행될수록 학습률을 점진적으로 감소\n",
        "                                            # 즉, 매 에포크(혹은 특정 단계)마다 학습률이 이전 학습률의 99%로 감소함을 의미합니다.\n",
        "        self.train_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/train.csv'\n",
        "        self.valid_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/valid.csv'\n",
        "        self.test_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/test.csv'\n",
        "        self.model_file = '/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/T2/best_model.pt'\n",
        "        self.extension = False\n",
        "        self.user_count = 15225             # preprocess 상에서의 users 값을 기입해야함\n",
        "        self.item_count = 641                # preprocess 상에서의 items 값을 기입해야함\n",
        "        self.review_count = 10               # 최대 리뷰 개수 설정\n",
        "        self.review_length = 80                  # review 최대 길이\n",
        "        self.lowest_review_count = 1        ## orignal 2\n",
        "        self.PAD_WORD = '<UNK>'             # review 길이가 부족한 경우 Padding으로 채움\n",
        "        self.kernel_count = 100              # Kernel 개수\n",
        "        self.kernel_size = 3                     # Window size\n",
        "        self.dropout_prob = 0.5              # Dropout rate\n",
        "        self.cnn_out_dim = 50                    # Latent Feature dimension"
      ],
      "metadata": {
        "id": "vqTun3grmW9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def date(f='%Y-%m-%d %H:%M:%S'):\n",
        "    return time.strftime(f, time.localtime())\n",
        "\n",
        "\n",
        "def calculate_mse(model, dataloader, device):\n",
        "    mse, sample_count = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            user_reviews, item_reviews, reviews, ratings, user_ids, item_ids = [x.to(device) for x in batch]\n",
        "            latent, predict = model(user_reviews, item_reviews, user_ids, item_ids)\n",
        "            mse += F.mse_loss(predict, ratings, reduction='sum').item()\n",
        "            sample_count += len(ratings)\n",
        "    return mse / sample_count  # mse of dataloader"
      ],
      "metadata": {
        "id": "FyisnKRsXtP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trans Network Dataset Setting"
      ],
      "metadata": {
        "id": "4bzVinekZQh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class TransNetsDataset(Dataset):\n",
        "    # 초기화 매서드(데이터셋 초기화 및 필요 변수 설정)\n",
        "    def __init__(self, data_path, word_dict, config):\n",
        "        self.word_dict = word_dict\n",
        "        self.r_count = config.review_count\n",
        "        self.r_length = config.review_length\n",
        "        self.lowest_r_count = config.lowest_review_count\n",
        "        self.PAD_WORD_idx = word_dict[config.PAD_WORD]\n",
        "\n",
        "        ## 데이터 읽기\n",
        "        df = pd.read_csv(data_path, header=None, names=['userID', 'itemID', 'review', 'rating'])\n",
        "\n",
        "        ## userID와 itemID를 숫자로 변환\n",
        "        df['userID'] = df['userID'].astype('category').cat.codes\n",
        "        df['itemID'] = df['itemID'].astype('category').cat.codes\n",
        "\n",
        "        ## 리뷰 데이터를 ID로 변환\n",
        "        df['review'] = df['review'].apply(self._review2id)\n",
        "        self.null_idx = set()\n",
        "\n",
        "        ## 사용자 및 아이템 리뷰 생성\n",
        "        user_reviews = self._get_reviews(df)\n",
        "        item_reviews = self._get_reviews(df, 'itemID', 'userID')\n",
        "\n",
        "        ## 리뷰, 평점, 사용자 및 아이템 ID를 텐서로 변환\n",
        "        reviews = [self._adjust_review_list([x], 1, self.r_length) for x in df['review']]\n",
        "        reviews = torch.LongTensor(reviews).view(-1, self.r_length)\n",
        "        rating = torch.Tensor(df['rating'].to_list()).view(-1, 1)\n",
        "        user_ids = torch.LongTensor(df['userID'].to_list()).view(-1, 1)\n",
        "        item_ids = torch.LongTensor(df['itemID'].to_list()).view(-1, 1)\n",
        "\n",
        "        self.user_reviews = user_reviews\n",
        "        self.item_reviews = item_reviews\n",
        "        self.reviews = reviews\n",
        "        self.rating = rating\n",
        "        self.user_ids = user_ids\n",
        "        self.item_ids = item_ids\n",
        "\n",
        "    # 인덱싱 매서드(특정 인덱스에 해당되는 샘플 데이터를 반환)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.user_reviews[idx], self.item_reviews[idx], self.reviews[idx], self.rating[idx],\\\n",
        "                self.user_ids[idx], self.item_ids[idx]\n",
        "\n",
        "    # 길이 메서드(데이터셋 전체 샘플 수를 반환)\n",
        "    def __len__(self):\n",
        "        return self.rating.shape[0]\n",
        "\n",
        "    # 사용자와 아이템 리뷰 생성 메서드 (특정 사용자 또는 아이템과 연관된 리뷰를 반환)\n",
        "    def _get_reviews(self, df, lead='userID', costar='itemID'):\n",
        "        reviews_by_lead = dict(list(df[[costar, 'review']].groupby(df[lead])))\n",
        "        lead_reviews = []\n",
        "        for idx, (lead_id, costar_id) in enumerate(zip(df[lead], df[costar])):\n",
        "\n",
        "        ## 관련없는 리뷰만 갖도록 필터링\n",
        "            df_data = reviews_by_lead[lead_id]\n",
        "            reviews = df_data['review'][df_data[costar] != costar_id].to_list()\n",
        "\n",
        "        ## 리뷰 정렬 및 변환\n",
        "            reviews = self._adjust_review_list(reviews, self.r_count, self.r_length)\n",
        "            lead_reviews.append(reviews)\n",
        "        return torch.LongTensor(lead_reviews)\n",
        "\n",
        "\n",
        "    # 리뷰 리스트 조정 메서드 (일정 개수(10개)와 길이(80개)로 조절)\n",
        "    def _adjust_review_list(self, reviews, r_count, r_length):\n",
        "        reviews = reviews[:r_count] + [[self.PAD_WORD_idx] * r_length] * (r_count - len(reviews))  # Certain count.\n",
        "        reviews = [r[:r_length] + [0] * (r_length - len(r)) for r in reviews]  # Certain length of review.\n",
        "        return reviews\n",
        "\n",
        "    # 리뷰를 단어 ID로 변환하는 매서드\n",
        "    def _review2id(self, review):\n",
        "        if not isinstance(review, str):  # 리뷰가 문자열인지 확인\n",
        "            return []  # 문자열이 아니면 빈 리스트 반환\n",
        "        return [self.word_dict.get(word, self.PAD_WORD_idx) for word in review.split()]\n",
        "\n"
      ],
      "metadata": {
        "id": "gle_2uA5mbT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def _review2id(self, review):  # Split a sentence into words, and map each word to a unique number by dict.\n",
        "    if not isinstance(review, str):\n",
        "        return []\n",
        "    wids = []\n",
        "    for word in review.split():\n",
        "        if word in self.word_dict:\n",
        "            wids.append(self.word_dict[word])  # word to unique number by dict.\n",
        "        else:\n",
        "            wids.append(self.PAD_WORD_idx)\n",
        "    return wids\n"
      ],
      "metadata": {
        "id": "w5TFAtYst-tV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Architecture"
      ],
      "metadata": {
        "id": "NMBpA0RonGK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.2 CNN Text Processor"
      ],
      "metadata": {
        "id": "cduTjfngUOwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, config, word_dim, review_count=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.kernel_count = config.kernel_count\n",
        "        self.review_count = review_count\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=word_dim,\n",
        "                out_channels=config.kernel_count,\n",
        "                kernel_size=config.kernel_size,\n",
        "                padding=(config.kernel_size - 1) // 2),         # out shape(new_batch_size, kernel_count, review_length)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1, config.review_length)),        # out shape(new_batch_size,kernel_count,1)\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(config.kernel_count * self.review_count, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, vec):                                     # input shape(new_batch_size, review_length, word2vec_dim)\n",
        "                                                                # (1280,80,64)\n",
        "        latent = self.conv(vec.permute(0, 2, 1))                # output shape(new_batch_size, kernel_count, 1)\n",
        "        latent = latent.view(-1, self.kernel_count * self.review_count)\n",
        "        latent = self.linear(latent)\n",
        "        return latent                                           # output shape(batch_size, cnn_out_dim)"
      ],
      "metadata": {
        "id": "gpTi_lXCUJLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.3 Dropout Layer and Factorization Machines(FM)"
      ],
      "metadata": {
        "id": "yntFrsw6UYYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factorization Machine(FM)"
      ],
      "metadata": {
        "id": "-pKR_bNbU5iP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FactorizationMachine(nn.Module):\n",
        "    def __init__(self, in_dim, k):                                 # in_dim=cnn_out_dim\n",
        "        super(FactorizationMachine, self).__init__()\n",
        "        self.v = nn.Parameter(torch.full([in_dim, k], 0.001))       # 3.2.5 TransNet-Ext\n",
        "        self.linear = nn.Linear(in_dim, 1)\n",
        "        self.linear.weight.data.normal_(mean=0, std=0.001)          # 3.2.5 TransNet-Ext\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear_part = self.linear(x)                                # input shape(batch_size, cnn_out_dim), output shape(batch_size, 1)\n",
        "        inter_part1 = torch.mm(x, self.v)\n",
        "        inter_part2 = torch.mm(x ** 2, self.v ** 2)\n",
        "        pair_interactions = torch.sum(inter_part1 ** 2 - inter_part2, dim=1)\n",
        "        output = linear_part.t() + 0.5 * pair_interactions\n",
        "        return output.view(-1, 1)                                   # output shape(batch_size, 1)"
      ],
      "metadata": {
        "id": "tIfdmyZuUYge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Network"
      ],
      "metadata": {
        "id": "qQqgX_VyUlNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SourceNet(nn.Module):\n",
        "    def __init__(self, config, word_emb, extend_model=False):\n",
        "        super(SourceNet, self).__init__()\n",
        "        self.extend_model = extend_model\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(word_emb))\n",
        "        self.cnn_u = CNN(config, word_dim=self.embedding.embedding_dim, review_count=config.review_count)           # 3.2.5 TransNet-Ext\n",
        "        self.cnn_i = CNN(config, word_dim=self.embedding.embedding_dim, review_count=config.review_count)           # 3.2.5 TransNet-Ext\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(config.cnn_out_dim * 2, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(config.cnn_out_dim, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=config.dropout_prob)\n",
        "        )\n",
        "\n",
        "        for m in self.transform.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(mean=0, std=0.1).clamp_(-1, 1)        # 3.2.4 Transform Hyperparameter\n",
        "                nn.init.constant_(m.bias.data, 0.1)\n",
        "\n",
        "\n",
        "\n",
        "        if self.extend_model:\n",
        "            self.emb_u = nn.Embedding(config.user_count, config.cnn_out_dim, padding_idx=0)\n",
        "            self.emb_i = nn.Embedding(config.item_count, config.cnn_out_dim, padding_idx=0)\n",
        "            self.fm = FactorizationMachine(in_dim=config.cnn_out_dim * 3, k=8)\n",
        "        else:\n",
        "            self.fm = FactorizationMachine(in_dim=config.cnn_out_dim, k=8)\n",
        "\n",
        "    def forward(self, user_reviews, item_reviews, user_ids, item_ids):              # shape(batch_size, review_count, review_length)\n",
        "\n",
        "        new_batch_size = user_reviews.shape[0] * user_reviews.shape[1]\n",
        "        u_vec = user_reviews.view(new_batch_size, -1)\n",
        "        i_vec = item_reviews.view(new_batch_size, -1)\n",
        "\n",
        "\n",
        "        u_vec = self.embedding(user_reviews.view(-1, user_reviews.shape[-1]))\n",
        "        i_vec = self.embedding(item_reviews.view(-1, item_reviews.shape[-1]))\n",
        "\n",
        "     ###########################################################\n",
        "\n",
        "        # Algorithm 3. Testing using TransNet\n",
        "            ## Step 1. Transform the input\n",
        "\n",
        "        user_latent = self.cnn_u(u_vec)\n",
        "        item_latent = self.cnn_i(i_vec)\n",
        "\n",
        "        concat_latent = torch.cat((user_latent, item_latent), dim=1)\n",
        "        trans_latent = self.transform(concat_latent)\n",
        "\n",
        "        if self.extend_model:\n",
        "            omega_u = self.emb_u(user_ids.view(-1))\n",
        "            omega_i = self.emb_i(item_ids.view(-1))\n",
        "            latent = torch.cat([omega_u, omega_i, trans_latent.detach()], dim=1)\n",
        "            prediction = self.fm(latent)\n",
        "        else:\n",
        "\n",
        "     ###########################################################\n",
        "\n",
        "            # Algorithm 3. Testing using TransNet\n",
        "                ## Step 2. Predict using the transformed input\n",
        "\n",
        "            prediction = self.fm(trans_latent.detach())         # Transform 레이어 출력(trans_latent)이 FM에 전달되어 평점 예측\n",
        "        return trans_latent, prediction\n",
        "\n",
        "    ###########################################################\n",
        "\n",
        "    # Algorithm 2. Transform the input\n",
        "\n",
        "    def trans_param(self):\n",
        "        return [x for x in self.cnn_u.parameters()] + \\\n",
        "               [x for x in self.cnn_i.parameters()] + \\\n",
        "               [x for x in self.transform.parameters()]\n",
        "\n",
        "    ###########################################################"
      ],
      "metadata": {
        "id": "VX22qgkYUlV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target Network"
      ],
      "metadata": {
        "id": "-SrqsMY6Vexf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TargetNet(nn.Module):\n",
        "    def __init__(self, config, word_emb):\n",
        "        super(TargetNet, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(word_emb))\n",
        "        self.cnn = CNN(config, word_dim=self.embedding.embedding_dim, review_count=1)\n",
        "        self.fm = nn.Sequential(\n",
        "            nn.Dropout(config.dropout_prob),                        # Since cnn did not dropout, dropout before FM.\n",
        "            FactorizationMachine(in_dim=config.cnn_out_dim, k=8)\n",
        "        )\n",
        "\n",
        "    def forward(self, reviews):                                     # input shape(batch_size, review_length)\n",
        "        vec = self.embedding(reviews)\n",
        "                                                                    # 추가: Embedding 결과 크기 확인\n",
        "                                                                    # [batch_size, review_length, embedding_dim] = 128,80,64\n",
        "        cnn_latent = self.cnn(vec)\n",
        "        prediction = self.fm(cnn_latent)\n",
        "        return cnn_latent, prediction\n"
      ],
      "metadata": {
        "id": "jpI7zC-TVgtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Test Function"
      ],
      "metadata": {
        "id": "LQ3OZrChVil3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2.6 Training"
      ],
      "metadata": {
        "id": "sTC-zpDMZ0Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 및 테스트 함수\n",
        "def train(train_dataloader, valid_dataloader, model_S, model_T, config, model_path):\n",
        "    print(f'{date()}## Start the training!')\n",
        "    train_mse = calculate_mse(model_S, train_dataloader, config.device)\n",
        "    valid_mse = calculate_mse(model_S, valid_dataloader, config.device)\n",
        "    print(f'{date()}#### Initial train mse {train_mse:.6f}, validation mse {valid_mse:.6f}')\n",
        "    start_time = time.perf_counter()\n",
        "\n",
        "    opt_S = torch.optim.Adam(model_S.parameters(), config.learning_rate, weight_decay=config.l2_regularization)\n",
        "    opt_trans = torch.optim.Adam(model_S.trans_param(), config.learning_rate, weight_decay=config.l2_regularization)\n",
        "    opt_T = torch.optim.Adam(model_T.parameters(), config.learning_rate, weight_decay=config.l2_regularization)\n",
        "    lr_sch_S = torch.optim.lr_scheduler.ExponentialLR(opt_S, config.learning_rate_decay)\n",
        "    lr_sch_trans = torch.optim.lr_scheduler.ExponentialLR(opt_trans, config.learning_rate_decay)\n",
        "    lr_sch_T = torch.optim.lr_scheduler.ExponentialLR(opt_T, config.learning_rate_decay)\n",
        "\n",
        "    best_loss, batch_step = 100, 0\n",
        "    model_T.train()\n",
        "    for epoch in range(config.train_epochs):\n",
        "        model_S.train()\n",
        "        total_loss, total_samples = 0, 0\n",
        "        for batch in train_dataloader:\n",
        "            user_reviews, item_reviews, reviews, ratings, user_ids, item_ids = [x.to(config.device) for x in batch]\n",
        "\n",
        "    ###########################################################\n",
        "\n",
        "            # Algorithm 1. Training Transnet\n",
        "\n",
        "                ## Step 1. Train Target Network on the actual review\n",
        "            latent_T, pred_T = model_T(reviews)\n",
        "            loss_T = F.l1_loss(pred_T, ratings)\n",
        "            opt_T.zero_grad()\n",
        "            loss_T.backward()\n",
        "\n",
        "                ## Step 2. Learn to Transform\n",
        "            latent_S, pred_S = model_S(user_reviews, item_reviews, user_ids, item_ids)\n",
        "            loss_trans = F.mse_loss(latent_S, latent_T.detach())\n",
        "            opt_trans.zero_grad()\n",
        "            loss_trans.backward()\n",
        "\n",
        "                ## Step 3. Train a predictor on the transform input\n",
        "            loss_S = F.l1_loss(pred_S, ratings, reduction='sum')\n",
        "            opt_S.zero_grad()\n",
        "            loss_S.backward()\n",
        "\n",
        "            opt_T.step()\n",
        "            opt_trans.step()\n",
        "            opt_S.step()\n",
        "\n",
        "            batch_step += 1\n",
        "            total_loss += loss_S.item()         # summing over all loss of source network\n",
        "            total_samples += len(pred_S)\n",
        "\n",
        "            if batch_step % 500 == 0:           # valid per 500 steps\n",
        "                model_S.eval()\n",
        "                valid_mse = calculate_mse(model_S, valid_dataloader, config.device)\n",
        "                if best_loss > valid_mse:\n",
        "                    best_loss = valid_mse\n",
        "                    torch.save(model_S, model_path)\n",
        "                print(f\"{date()}###### Step {batch_step:3d}; validation mse {valid_mse:.6f}\")\n",
        "                model_S.train()\n",
        "\n",
        "        lr_sch_S.step()\n",
        "        lr_sch_trans.step()\n",
        "        lr_sch_T.step()\n",
        "        valid_mse = calculate_mse(model_S, valid_dataloader, config.device)\n",
        "        if best_loss > valid_mse:\n",
        "            best_loss = valid_mse\n",
        "            torch.save(model_S, model_path)\n",
        "        print(f\"{date()}#### Epoch {epoch:3d}; train mse {total_loss/total_samples:.6f}; validation mse {valid_mse:.6f}\")\n",
        "\n",
        "    print(f'{date()}## End of training!')\n",
        "\n",
        "###########################################################\n",
        "\n",
        "# Algorithm 3. Testing using TransNet\n",
        "    ## Step 3. Final Calculation\n",
        "\n",
        "def test(dataloader, best_model, config):\n",
        "    print(f'{date()}## Start the testing!')\n",
        "    test_loss = calculate_mse(best_model, dataloader, config.device)\n",
        "    print(f\"{date()}## Test end, test mse is {test_loss:.6f}\")\n",
        "\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "B1U495JSmodF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "best model = SourceNet과 TargetNet에서 Transform Layer를 통해 도출된 잠재특성(latent)의 표현\n",
        "\n",
        "\n",
        "TargetNet은 평점과 고객이 동시에 존재하는 경우이기에 CNN과 Factorization Machine(FM)으로 평점 예측 수행함."
      ],
      "metadata": {
        "id": "nHxGllbr2I_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SourceNet는 forward Function에 기재되어있다.**\n",
        "\n",
        "user_latent = self.cnn_u(u_vec)\n",
        "\n",
        "item_latent = self.cnn_i(i_vec)\n",
        "\n",
        "concat_latent = torch.cat((user_latent, item_latent), dim=1)\n",
        "\n",
        "trans_latent = self.transform(concat_latent)"
      ],
      "metadata": {
        "id": "3upeenL33U8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test and Result"
      ],
      "metadata": {
        "id": "Jj6Lu0gbZp5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import inspect\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import time\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "QqAt93dan3Z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word Embedding과 Dictionary pickle file 경로 확인"
      ],
      "metadata": {
        "id": "r1G17znFyaSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# 파일 경로 확인\n",
        "assert os.path.exists('/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/word_emb.pkl'), \"word_emb.pkl not found\"\n",
        "assert os.path.exists('/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/dict.pkl'), \"dict.pkl not found\"\n"
      ],
      "metadata": {
        "id": "y938SzDZo0A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행부\n",
        "if __name__ == '__main__':\n",
        "    config = Config()\n",
        "    print(config)\n",
        "\n",
        "    # 파일 경로 확인\n",
        "    assert os.path.exists(config.train_file), \"Train file not found\"\n",
        "    assert os.path.exists(config.valid_file), \"Valid file not found\"\n",
        "    assert os.path.exists(config.test_file), \"Test file not found\"\n",
        "\n",
        "    print(\"## Load word2vec and data...\")\n",
        "    word_emb = pickle.load(open('/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/word_emb.pkl', 'rb'), encoding='iso-8859-1')\n",
        "    word_dict = pickle.load(open('/content/drive/MyDrive/IDS/amaxon reviews 2023/Transnet/dict.pkl', 'rb'), encoding='iso-8859-1')\n",
        "\n",
        "    # 데이터셋 생성\n",
        "    train_dataset = TransNetsDataset(config.train_file, word_dict, config)\n",
        "    valid_dataset = TransNetsDataset(config.valid_file, word_dict, config)\n",
        "    test_dataset = TransNetsDataset(config.test_file, word_dict, config)\n",
        "\n",
        "    # 데이터셋 크기 출력\n",
        "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "    print(f\"Valid dataset size: {len(valid_dataset)}\")\n",
        "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "    # 데이터 로더 생성\n",
        "    train_dlr = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    valid_dlr = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    test_dlr = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "\n",
        "    source_model = SourceNet(config, word_emb, extend_model=config.extension).to(config.device)\n",
        "    target_model = TargetNet(config, word_emb).to(config.device)\n",
        "\n",
        "    os.makedirs(os.path.dirname(config.model_file), exist_ok=True)\n",
        "\n",
        "    train(train_dlr, valid_dlr, source_model, target_model, config, config.model_file)\n",
        "    test(test_dlr, torch.load(config.model_file), config)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjE6CkvKjjaL",
        "outputId": "711e1da0-a01d-45bd-b954-7c3d289dfc4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.Config object at 0x7c20857c3520>\n",
            "## Load word2vec and data...\n",
            "Train dataset size: 12795\n",
            "Valid dataset size: 1599\n",
            "Test dataset size: 1600\n",
            "2024-12-19 10:55:57## Start the training!\n",
            "2024-12-19 10:55:58#### Initial train mse 17.205638, validation mse 17.108458\n",
            "2024-12-19 10:55:59#### Epoch   0; train mse 2.306171; validation mse 3.650761\n",
            "2024-12-19 10:56:00#### Epoch   1; train mse 1.568476; validation mse 3.483900\n",
            "2024-12-19 10:56:01#### Epoch   2; train mse 1.524776; validation mse 3.353805\n",
            "2024-12-19 10:56:02#### Epoch   3; train mse 1.492822; validation mse 3.248811\n",
            "2024-12-19 10:56:03###### Step 500; validation mse 2.477248\n",
            "2024-12-19 10:56:03#### Epoch   4; train mse 1.484235; validation mse 3.192119\n",
            "2024-12-19 10:56:04#### Epoch   5; train mse 1.459969; validation mse 3.300853\n",
            "2024-12-19 10:56:05#### Epoch   6; train mse 1.428232; validation mse 3.157721\n",
            "2024-12-19 10:56:06#### Epoch   7; train mse 1.414320; validation mse 3.043463\n",
            "2024-12-19 10:56:07#### Epoch   8; train mse 1.396352; validation mse 3.021115\n",
            "2024-12-19 10:56:08###### Step 1000; validation mse 2.533133\n",
            "2024-12-19 10:56:08#### Epoch   9; train mse 1.379047; validation mse 2.920357\n",
            "2024-12-19 10:56:09#### Epoch  10; train mse 1.368798; validation mse 3.018130\n",
            "2024-12-19 10:56:10#### Epoch  11; train mse 1.355127; validation mse 2.860276\n",
            "2024-12-19 10:56:11#### Epoch  12; train mse 1.342024; validation mse 3.031655\n",
            "2024-12-19 10:56:12#### Epoch  13; train mse 1.334807; validation mse 3.083713\n",
            "2024-12-19 10:56:14###### Step 1500; validation mse 2.684822\n",
            "2024-12-19 10:56:14#### Epoch  14; train mse 1.328586; validation mse 3.060491\n",
            "2024-12-19 10:56:14## End of training!\n",
            "2024-12-19 10:56:14## Start the testing!\n",
            "2024-12-19 10:56:14## Test end, test mse is 2.415422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-09779ddf4eda>:36: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test(test_dlr, torch.load(config.model_file), config)\n"
          ]
        }
      ]
    }
  ]
}