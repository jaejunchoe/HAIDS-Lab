{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk2dH/wdqhQ+elyz7DVhf6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaejunchoe/HAIDS-Lab/blob/main/utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-tEhhtrRQss"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def date(f='%Y-%m-%d %H:%M:%S'):\n",
        "    return time.strftime(f, time.localtime())\n",
        "\n",
        "# glove.6B.50d.txt 파일 load하고 embedding하는 함수\n",
        "def load_embedding(word2vec_file):\n",
        "    with open(word2vec_file, encoding='utf-8') as f:\n",
        "        word_emb = [[0]]\n",
        "        word_dict = {'<UNK>': 0}\n",
        "        for line in f.readlines():\n",
        "            tokens = line.split(' ')\n",
        "            word_emb.append([float(i) for i in tokens[1:]])\n",
        "            word_dict[tokens[0]] = len(word_dict)\n",
        "        word_emb[0] = [0] * len(word_emb[1])\n",
        "    return word_emb, word_dict\n",
        "\n",
        "\n",
        "# MSE 계산하는 함수 -> train과 valid에서 사용\n",
        "def predict_mse(model, dataloader, device):\n",
        "    mse, sample_count = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            user_reviews, item_reviews, ratings = map(lambda x: x.to(device), batch)\n",
        "            predict = model(user_reviews, item_reviews)\n",
        "            mse += F.mse_loss(predict, ratings, reduction='sum').item()\n",
        "            sample_count += len(ratings)\n",
        "    return mse / sample_count\n",
        "\n",
        "# Pytorch의 Dataset 클래스를 확장해서 DeepCoNN 모델의 학습에 적합한 데이터셋을 생성하는 Class\n",
        "class DeepCoNNDataset(Dataset):\n",
        "\n",
        "    ## csv 파일을 읽고 모델 입력 형식에 맞게 바꾸는 함수\n",
        "    def __init__(self, data_path, word_dict, config, retain_rui=True):\n",
        "        self.word_dict = word_dict\n",
        "        self.config = config\n",
        "        self.retain_rui = retain_rui                        # 리뷰 포함에 대한 조건\n",
        "        self.PAD_WORD_idx = self.word_dict[config.PAD_WORD]\n",
        "        self.review_length = config.review_length\n",
        "        self.review_count = config.review_count\n",
        "        self.lowest_r_count = config.lowest_review_count\n",
        "\n",
        "        df = pd.read_csv(data_path, header=None, names=['userID', 'itemID', 'review', 'rating'])\n",
        "        df['review'] = df['review'].apply(self._review2id)\n",
        "        self.sparse_idx = set()\n",
        "\n",
        "        user_reviews = self._get_reviews(df)\n",
        "        item_reviews = self._get_reviews(df, 'itemID', 'userID')\n",
        "        rating = torch.Tensor(df['rating'].to_list()).view(-1, 1)\n",
        "\n",
        "        # 희소 데이터(self.sparse_idx)를 제외하고 필터 -> lowest_review_count = 0이기에 손실되는 데이터 없을 것\n",
        "        self.user_reviews = user_reviews[[idx for idx in range(user_reviews.shape[0]) if idx not in self.sparse_idx]]\n",
        "        self.item_reviews = item_reviews[[idx for idx in range(item_reviews.shape[0]) if idx not in self.sparse_idx]]\n",
        "        self.rating = rating[[idx for idx in range(rating.shape[0]) if idx not in self.sparse_idx]]\n",
        "\n",
        "\n",
        "    ## 데이터셋에서 특정 idx로 데이터를 반환함 -> (user_reviews, item_reviews, rating)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.user_reviews[idx], self.item_reviews[idx], self.rating[idx]\n",
        "\n",
        "\n",
        "    ## 데이터셋 전체 길이 반환\n",
        "    def __len__(self):\n",
        "        return self.rating.shape[0]\n",
        "\n",
        "\n",
        "    ## 사용자 또는 아이템 단위로 리뷰 데이터를 그룹화하고, 최대 리뷰 개수(10개)에 따라 정리\n",
        "    def _get_reviews(self, df, lead='userID', costar='itemID'):\n",
        "        reviews_by_lead = dict(list(df[[costar, 'review']].groupby(df[lead])))\n",
        "        lead_reviews = []\n",
        "        for idx, (lead_id, costar_id) in enumerate(zip(df[lead], df[costar])):\n",
        "            df_data = reviews_by_lead[lead_id]\n",
        "\n",
        "\n",
        "            # self.retain_rui = True: 사용자가 작성한 모든 리뷰를 가져와\n",
        "            # true이기에 else가 실행되지않을 것 -> reviews = df_data['review'].to_list()가 이미 모든 리뷰를 포함하기 때문\n",
        "            reviews = df_data['review'].to_list() if self.retain_rui else df_data['review'][df_data[costar] != costar_id].to_list()\n",
        "\n",
        "\n",
        "            if len(reviews) < self.lowest_r_count:\n",
        "                self.sparse_idx.add(idx)\n",
        "            reviews = self._adjust_review_list(reviews, self.review_length, self.review_count)      # 개수와 길이 조정\n",
        "            lead_reviews.append(reviews)\n",
        "        return torch.LongTensor(lead_reviews)\n",
        "\n",
        "\n",
        "    ## 리뷰 데이터를 고정된 리뷰 수(review_count)와 리뷰 길이(review_length)로 조정\n",
        "    def _adjust_review_list(self, reviews, r_length, r_count):\n",
        "        reviews = reviews[:r_count] + [[self.PAD_WORD_idx] * r_length] * (r_count - len(reviews))\n",
        "        reviews = [r[:r_length] + [0] * (r_length - len(r)) for r in reviews]\n",
        "        return reviews\n",
        "\n",
        "    ## 리뷰 문자열을 단어 임베딩 인덱스 리스트로 변환\n",
        "    def _review2id(self, review):\n",
        "        if not isinstance(review, str):\n",
        "            return []\n",
        "        return [self.word_dict.get(word, self.PAD_WORD_idx) for word in review.split()]"
      ]
    }
  ]
}
