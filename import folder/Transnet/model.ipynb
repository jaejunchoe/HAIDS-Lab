{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyzZAguYdxaqhQxCQHR01J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaejunchoe/HAIDS-Lab/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDSgWTbPDffs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, config, word_dim, review_count=1):\n",
        "        super(CNN, self).__init__()\n",
        "        self.kernel_count = config.kernel_count\n",
        "        self.review_count = review_count\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=word_dim,\n",
        "                out_channels=config.kernel_count,\n",
        "                kernel_size=config.kernel_size,\n",
        "                padding=(config.kernel_size - 1) // 2),         # out shape(new_batch_size, kernel_count, review_length)\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(1, config.review_length)),        # out shape(new_batch_size,kernel_count,1)\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(config.kernel_count * self.review_count, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, vec):                                     # input shape(new_batch_size, review_length, word2vec_dim)\n",
        "                                                                # (1280,80,64)\n",
        "        latent = self.conv(vec.permute(0, 2, 1))                # output shape(new_batch_size, kernel_count, 1)\n",
        "        latent = latent.view(-1, self.kernel_count * self.review_count)\n",
        "        latent = self.linear(latent)\n",
        "        return latent                                           # output shape(batch_size, cnn_out_dim)\n",
        "\n",
        "\n",
        "class FactorizationMachine(nn.Module):\n",
        "    def __init__(self, in_dim, k):                                 # in_dim=cnn_out_dim\n",
        "        super(FactorizationMachine, self).__init__()\n",
        "        self.v = nn.Parameter(torch.full([in_dim, k], 0.001))       # 3.2.5 TransNet-Ext\n",
        "        self.linear = nn.Linear(in_dim, 1)\n",
        "        self.linear.weight.data.normal_(mean=0, std=0.001)          # 3.2.5 TransNet-Ext\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear_part = self.linear(x)                                # input shape(batch_size, cnn_out_dim), output shape(batch_size, 1)\n",
        "        inter_part1 = torch.mm(x, self.v)\n",
        "        inter_part2 = torch.mm(x ** 2, self.v ** 2)\n",
        "        pair_interactions = torch.sum(inter_part1 ** 2 - inter_part2, dim=1)\n",
        "        output = linear_part.t() + 0.5 * pair_interactions\n",
        "        return output.view(-1, 1)                                   # output shape(batch_size, 1)\n",
        "\n",
        "\n",
        "class SourceNet(nn.Module):\n",
        "    def __init__(self, config, word_emb, extend_model=False):\n",
        "        super(SourceNet, self).__init__()\n",
        "        self.extend_model = extend_model\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(word_emb))\n",
        "        self.cnn_u = CNN(config, word_dim=self.embedding.embedding_dim, review_count=config.review_count)           # 3.2.5 TransNet-Ext\n",
        "        self.cnn_i = CNN(config, word_dim=self.embedding.embedding_dim, review_count=config.review_count)           # 3.2.5 TransNet-Ext\n",
        "        self.transform = nn.Sequential(\n",
        "            nn.Linear(config.cnn_out_dim * 2, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(config.cnn_out_dim, config.cnn_out_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(p=config.dropout_prob)\n",
        "        )\n",
        "\n",
        "        for m in self.transform.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(mean=0, std=0.1).clamp_(-1, 1)        # 3.2.4 Transform Hyperparameter\n",
        "                nn.init.constant_(m.bias.data, 0.1)\n",
        "\n",
        "\n",
        "\n",
        "        if self.extend_model:\n",
        "            self.emb_u = nn.Embedding(config.user_count, config.cnn_out_dim, padding_idx=0)\n",
        "            self.emb_i = nn.Embedding(config.item_count, config.cnn_out_dim, padding_idx=0)\n",
        "            self.fm = FactorizationMachine(in_dim=config.cnn_out_dim * 3, k=8)\n",
        "        else:\n",
        "            self.fm = FactorizationMachine(in_dim=config.cnn_out_dim, k=8)\n",
        "\n",
        "    def forward(self, user_reviews, item_reviews, user_ids, item_ids):              # shape(batch_size, review_count, review_length)\n",
        "\n",
        "        new_batch_size = user_reviews.shape[0] * user_reviews.shape[1]\n",
        "        u_vec = user_reviews.view(new_batch_size, -1)\n",
        "        i_vec = item_reviews.view(new_batch_size, -1)\n",
        "\n",
        "\n",
        "        u_vec = self.embedding(user_reviews.view(-1, user_reviews.shape[-1]))\n",
        "        i_vec = self.embedding(item_reviews.view(-1, item_reviews.shape[-1]))\n",
        "\n",
        "     ###########################################################\n",
        "\n",
        "        # Algorithm 3. Testing using TransNet\n",
        "            ## Step 1. Transform the input\n",
        "\n",
        "        user_latent = self.cnn_u(u_vec)\n",
        "        item_latent = self.cnn_i(i_vec)\n",
        "\n",
        "        concat_latent = torch.cat((user_latent, item_latent), dim=1)\n",
        "        trans_latent = self.transform(concat_latent)\n",
        "\n",
        "        if self.extend_model:\n",
        "            omega_u = self.emb_u(user_ids.view(-1))\n",
        "            omega_i = self.emb_i(item_ids.view(-1))\n",
        "            latent = torch.cat([omega_u, omega_i, trans_latent.detach()], dim=1)\n",
        "            prediction = self.fm(latent)\n",
        "        else:\n",
        "\n",
        "     ###########################################################\n",
        "\n",
        "            # Algorithm 3. Testing using TransNet\n",
        "                ## Step 2. Predict using the transformed input\n",
        "\n",
        "            prediction = self.fm(trans_latent.detach())         # Transform 레이어 출력(trans_latent)이 FM에 전달되어 평점 예측\n",
        "        return trans_latent, prediction\n",
        "\n",
        "    ###########################################################\n",
        "\n",
        "    # Algorithm 2. Transform the input\n",
        "\n",
        "    def trans_param(self):\n",
        "        return [x for x in self.cnn_u.parameters()] + \\\n",
        "               [x for x in self.cnn_i.parameters()] + \\\n",
        "               [x for x in self.transform.parameters()]\n",
        "\n",
        "    ###########################################################\n",
        "\n",
        "\n",
        "\n",
        "class TargetNet(nn.Module):\n",
        "    def __init__(self, config, word_emb):\n",
        "        super(TargetNet, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(word_emb))\n",
        "        self.cnn = CNN(config, word_dim=self.embedding.embedding_dim, review_count=1)\n",
        "        self.fm = nn.Sequential(\n",
        "            nn.Dropout(config.dropout_prob),                        # Since cnn did not dropout, dropout before FM.\n",
        "            FactorizationMachine(in_dim=config.cnn_out_dim, k=8)\n",
        "        )\n",
        "\n",
        "    def forward(self, reviews):                                     # input shape(batch_size, review_length)\n",
        "        vec = self.embedding(reviews)\n",
        "                                                                    # 추가: Embedding 결과 크기 확인\n",
        "                                                                    # [batch_size, review_length, embedding_dim] = 128,80,64\n",
        "        cnn_latent = self.cnn(vec)\n",
        "        prediction = self.fm(cnn_latent)\n",
        "        return cnn_latent, prediction\n"
      ]
    }
  ]
}
